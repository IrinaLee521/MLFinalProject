{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The nPrint Machine Learning Pipeline\n",
    "\n",
    "This notebook is designed to give you a **very** simple example of how to use nPrint in a generic machine learning pipeline and the rapid pace at which we can train new models and test new ideas on network traffic. Note that this example is simply to show the pipeline, not to test a hard problem. The traffic collected is to the same website over the course of about 15 seconds.\n",
    "\n",
    "\n",
    "### Requirements\n",
    "\n",
    "nPrint must be installed into $PATH for external commands to work\n",
    "\n",
    "### Directory Sturcture\n",
    "\n",
    "There are 2 `pcap` files in this directory\n",
    "1. `port443.pcap` - a small trace of packets sent and received over https  \n",
    "2. `port80.pcap` - a small trace of packets sent and received over http"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating nPrints from Traffic\n",
    "\n",
    "First, lets generate nPrints from each traffic trace. Let's **only** include the TCP headers in the nPrints for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets examine the nPrints, which can be directly loaded with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'TrafficLabelling/Friday-WorkingHours-Morning.pcap_ISCX.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m friday \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrafficLabelling/Friday-WorkingHours-Morning.pcap_ISCX.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFriday nPrint: Number of Packets: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m, Features per packet: \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(friday\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], friday\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1727\u001b[0m     is_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1728\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1729\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1740\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:857\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    856\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    866\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'TrafficLabelling/Friday-WorkingHours-Morning.pcap_ISCX.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "friday = pd.read_csv('TrafficLabelling/Friday-WorkingHours-Morning.pcap_ISCX.csv', index_col=0)\n",
    "\n",
    "print('Friday nPrint: Number of Packets: {0}, Features per packet: {1}'.format(friday.shape[0], friday.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'friday' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfriday\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'friday' is not defined"
     ]
    }
   ],
   "source": [
    "friday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nPrint to Machine Learning Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We label each sample with its corresponding operating system by matching its source IP address to the OS found\n",
    "on this website https://www.unb.ca/cic/datasets/ids-2017.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'friday' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m samples \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 6\u001b[0m friday \u001b[38;5;241m=\u001b[39m \u001b[43mfriday\u001b[49m\u001b[38;5;241m.\u001b[39mreplace([np\u001b[38;5;241m.\u001b[39minf, \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf], np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m      7\u001b[0m friday \u001b[38;5;241m=\u001b[39m friday\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# label the operating system based on IP address from this website: https://www.unb.ca/cic/datasets/ids-2017.html\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'friday' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "samples = []\n",
    "labels = []\n",
    "\n",
    "friday = friday.replace([np.inf, -np.inf], np.nan)\n",
    "friday = friday.dropna()\n",
    "# label the operating system based on IP address from this website: https://www.unb.ca/cic/datasets/ids-2017.html\n",
    "ip_to_os = {'205.174.165.73': 'Kali', '205.174.165.69': 'Win', '205.174.165.70': 'Win', '205.174.165.71': 'Win', '192.168.10.50': 'Web server 16 Public', '192.168.10.205.174.165.68': 'Web server 16 Public', '192.168.10.51': 'Ubuntu server 12 Public', '192.168.10.205.174.165.66': 'Ubuntu server 12 Public', '192.168.10.19': 'Ubuntu 14.4, 32B', '192.168.10.17': 'Ubuntu 14.4, 64B', '192.168.10.16': 'Ubuntu 16.4, 32B', '192.168.10.12': 'Ubuntu 16.4, 64B', '192.168.10.9': 'Win 7 Pro, 64B', '192.168.10.5': 'Win 8.1, 64B', '192.168.10.8': 'Win Vista, 64B', '192.168.10.14': 'Win 10, pro 32B', '192.168.10.15': 'Win 10, 64B', '192.168.10.25': 'MAC'}\n",
    "labels = friday[' Source IP'].apply(lambda x : \"Other\" if x not in ip_to_os else ip_to_os[x])\n",
    "samples = friday.drop([' Source IP', ' Source Port', ' Destination IP', ' Destination Port', ' Timestamp'], axis=1)\n",
    "samples = samples._get_numeric_data()\n",
    "samples = samples.reset_index(drop=True)\n",
    "\n",
    "samples = samples.astype(np.float32)\n",
    "samples.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Classifier\n",
    "\n",
    "We're already ready to train and test a model on the traffic we gathered. Let's split the data into training and testing data, train a model, and get a stat report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "                              0.98      0.99      0.98     13986\n",
      "                   Kali       0.94      0.92      0.93       158\n",
      "                    MAC       0.88      0.80      0.84      1738\n",
      "       Ubuntu 14.4, 32B       0.59      0.61      0.60      3820\n",
      "       Ubuntu 14.4, 64B       0.47      0.38      0.42      2522\n",
      "       Ubuntu 16.4, 32B       0.48      0.40      0.43      2432\n",
      "       Ubuntu 16.4, 64B       0.52      0.62      0.56      4160\n",
      "Ubuntu server 12 Public       0.96      0.91      0.94       263\n",
      "   Web server 16 Public       0.84      0.87      0.86       967\n",
      "            Win 10, 64B       0.48      0.48      0.48      3270\n",
      "        Win 10, pro 32B       0.44      0.36      0.40      2585\n",
      "         Win 7 Pro, 64B       0.51      0.54      0.53      4426\n",
      "           Win 8.1, 64B       0.57      0.59      0.58      4828\n",
      "         Win Vista, 64B       0.52      0.51      0.51      2573\n",
      "\n",
      "               accuracy                           0.68     47728\n",
      "              macro avg       0.66      0.64      0.65     47728\n",
      "           weighted avg       0.68      0.68      0.68     47728\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(samples, labels)\n",
    "\n",
    "# Initialize Classifier\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=None, min_samples_split=2, random_state=0)\n",
    "\n",
    "# Train \n",
    "clf.fit(X_train, y_train) \n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Statistics\n",
    "\n",
    "# First, lets get a stat report about the precision and recall:\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "# Let's also get the ROC AUC score while we're here, which requires a probability instead of just the prediction\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "# predict_proba gives us a probability estimate of each class, while roc_auc just cares about the \"positive\" class\n",
    "y_pred_proba_pos = [sublist[1] for sublist in y_pred_proba]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-6005d252f7bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_proba_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ovo\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ROC AUC Score: {0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raise'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         return _multiclass_roc_auc_score(y_true, y_score, labels,\n\u001b[0m\u001b[1;32m    538\u001b[0m                                          multi_class, average, sample_weight)\n\u001b[1;32m    539\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_multiclass_roc_auc_score\u001b[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[1;32m    593\u001b[0m     \"\"\"\n\u001b[1;32m    594\u001b[0m     \u001b[0;31m# validation of the input y_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m         raise ValueError(\n\u001b[1;32m    597\u001b[0m             \u001b[0;34m\"Target scores need to be probabilities for multiclass \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     45\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     46\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "roc = roc_auc_score(y_test, y_pred_proba_pos, multi_class=\"ovo\")\n",
    "print('ROC AUC Score: {0}'.format(roc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the model\n",
    "\n",
    "nPrint's alignment of each packet allows for understanding the specific features (parts of the packet) that are driving the model's performance. It turns out that the options that are being set in the TCP header is actually more important than the port numbers themselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('tcp_opt_67', 0.044505100017426795)\n",
      "('tcp_opt_6', 0.016730629081809993)\n",
      "('tcp_opt_55', 0.01523586076750689)\n",
      "('tcp_opt_20', 0.014805459966212969)\n",
      "('tcp_opt_44', 0.014620986047823093)\n",
      "('tcp_opt_40', 0.013847115275440285)\n",
      "('tcp_opt_24', 0.013612515683690887)\n",
      "('tcp_opt_48', 0.013313782454536936)\n",
      "('tcp_opt_72', 0.013230183523847874)\n",
      "('tcp_opt_77', 0.012961325676052151)\n",
      "('tcp_opt_29', 0.012785034592834255)\n",
      "('tcp_opt_32', 0.012665315285534077)\n",
      "('tcp_opt_50', 0.01253854986829483)\n",
      "('tcp_opt_37', 0.012524446118117365)\n",
      "('tcp_opt_49', 0.012504783737309715)\n",
      "('tcp_opt_42', 0.01246014726713846)\n",
      "('tcp_opt_54', 0.012341988396905099)\n",
      "('tcp_opt_68', 0.012192884127280043)\n",
      "('tcp_opt_64', 0.01216579933207458)\n",
      "('tcp_opt_75', 0.011726936074581147)\n"
     ]
    }
   ],
   "source": [
    "# Get Raw feature importances\n",
    "feature_importances = clf.feature_importances_\n",
    "# Match the feature names we know with the importances\n",
    "named_importances = []\n",
    "for column_name, importance in zip(nprint_80.columns, feature_importances):\n",
    "    named_importances.append((column_name, importance))\n",
    "# Sort the named feature importances\n",
    "sorted_feature_importances = sorted(named_importances, key=lambda tup: tup[1], reverse=True)\n",
    "# Now lets print the top 20 important features (bits)\n",
    "print(*sorted_feature_importances[0:20], sep='\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rapidly testing different versions of the problem\n",
    "\n",
    "now that we have a generic pipeline, we can leverage nPrint's flags to generate different versions of nPrints. Let's test a version of this classification problem using **only** the IPv4 Headers of the packets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   encrypted       1.00      1.00      1.00       628\n",
      " unencrypted       1.00      1.00      1.00       603\n",
      "\n",
      "    accuracy                           1.00      1231\n",
      "   macro avg       1.00      1.00      1.00      1231\n",
      "weighted avg       1.00      1.00      1.00      1231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate nPrints\n",
    "cmd_80 = 'nprint -P port80.pcap -4  -W port80.npt'\n",
    "cmd_443 = 'nprint -P port443.pcap -4 -W port443.npt'\n",
    "!{cmd_80}\n",
    "!{cmd_443}\n",
    "\n",
    "# Load nPrints\n",
    "nprint_80 = pd.read_csv('port80.npt', index_col=0)\n",
    "nprint_443 = pd.read_csv('port443.npt', index_col=0)\n",
    "\n",
    "# Assoicate with Labels\n",
    "samples = []\n",
    "labels = []\n",
    "for _, row in nprint_80.iterrows():\n",
    "    samples.append(np.array(row))\n",
    "    labels.append('unencrypted')\n",
    "\n",
    "for _, row in nprint_443.iterrows():\n",
    "    samples.append(np.array(row))\n",
    "    labels.append('encrypted')\n",
    "    \n",
    "# Train and Test the Classifier\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(samples, labels)\n",
    "# Initialize Classifier\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=None, min_samples_split=2, random_state=0)\n",
    "# Train \n",
    "clf.fit(X_train, y_train) \n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "# Statistics\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about Testing using just the first 30 payload bytes in each packet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   encrypted       0.64      0.65      0.64       630\n",
      " unencrypted       0.63      0.62      0.62       601\n",
      "\n",
      "    accuracy                           0.63      1231\n",
      "   macro avg       0.63      0.63      0.63      1231\n",
      "weighted avg       0.63      0.63      0.63      1231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate nPrints\n",
    "cmd_80 = 'nprint -P port80.pcap -p 30 -W port80.npt'\n",
    "cmd_443 = 'nprint -P port443.pcap -p 30 -W port443.npt'\n",
    "!{cmd_80}\n",
    "!{cmd_443}\n",
    "\n",
    "# Load nPrints\n",
    "nprint_80 = pd.read_csv('port80.npt', index_col=0)\n",
    "nprint_443 = pd.read_csv('port443.npt', index_col=0)\n",
    "\n",
    "# Assoicate with Labels\n",
    "samples = []\n",
    "labels = []\n",
    "for _, row in nprint_80.iterrows():\n",
    "    samples.append(np.array(row))\n",
    "    labels.append('unencrypted')\n",
    "\n",
    "for _, row in nprint_443.iterrows():\n",
    "    samples.append(np.array(row))\n",
    "    labels.append('encrypted')\n",
    "    \n",
    "# Train and Test the Classifier\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(samples, labels)\n",
    "# Initialize Classifier\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=None, min_samples_split=2, random_state=0)\n",
    "# Train \n",
    "clf.fit(X_train, y_train) \n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "# Statistics\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A much harder problem, with a much lower score. It may be likely that many packets don't have a payload at all, making it impossible to guess the traffic! What if we remove those packets from our dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   encrypted       0.67      1.00      0.80       440\n",
      " unencrypted       1.00      0.24      0.39       284\n",
      "\n",
      "    accuracy                           0.70       724\n",
      "   macro avg       0.84      0.62      0.60       724\n",
      "weighted avg       0.80      0.70      0.64       724\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load nPrints\n",
    "nprint_80 = pd.read_csv('port80.npt', index_col=0)\n",
    "nprint_443 = pd.read_csv('port443.npt', index_col=0)\n",
    "\n",
    "# Assoicate with Labels\n",
    "samples = []\n",
    "labels = []\n",
    "for _, row in nprint_80.iterrows():\n",
    "    # Check for no payload, all bits will be -1. There are more efficient ways to do this\n",
    "    if len(set(row)) == 1:\n",
    "        continue\n",
    "    samples.append(np.array(row))\n",
    "    labels.append('unencrypted')\n",
    "\n",
    "for _, row in nprint_443.iterrows():\n",
    "    # Check for no payload, all bits will be -1. There are more efficient ways to do this\n",
    "    if len(set(row)) == 1:\n",
    "        continue\n",
    "    samples.append(np.array(row))\n",
    "    labels.append('encrypted')\n",
    "    \n",
    "# Train and Test the Classifier\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(samples, labels)\n",
    "# Initialize Classifier\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=None, min_samples_split=2, random_state=0)\n",
    "# Train \n",
    "clf.fit(X_train, y_train) \n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "# Statistics\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Hopefully this gives you a better idea of how nPrint can be used to rapidly train and test models for different traffic analysis problems. While this problem was contrived and simple, the same basic steps can be performed for any single-packet classification problem. If you want to train and test using **sets** of packets as input to a model, you'll either need a model that can handle that input, such as a CNN, or to flatten the 2D packet sample into a 1d sample for use with a model such as the random forest above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
